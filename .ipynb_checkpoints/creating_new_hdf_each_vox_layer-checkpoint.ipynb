{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('/home/jan/Documents/Voxel_Erstellung/HDFs/New')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dock_df_to_zero(df, minX, minY):\n",
    "    if minX >= 0 and minY >=0:\n",
    "        df['x'] = df['x'] - minX\n",
    "        df['y'] = df['y'] - minY\n",
    "    elif minX < 0 and minY <0:\n",
    "        df['x'] = df['x'] + abs(minX)\n",
    "        df['y'] = df['y'] + abs(minY)\n",
    "    elif minX >= 0 and minY <0:\n",
    "        df['x'] = df['x'] - minX\n",
    "        df['y'] = df['y'] + abs(minY)\n",
    "    elif minX < 0 and min >= 0:\n",
    "        df['x'] = df['x'] + abs(minX)\n",
    "        df['y'] = df['y'] - minY\n",
    "    return df\n",
    "#-----------------------------------------------------------------------\n",
    "def get_true_min_maxX (h5_path, part_name, max_slice_number):\n",
    "\n",
    "    minX = []\n",
    "    maxX = []\n",
    "    for num_slice in range(max_slice_number):\n",
    "        with h5py.File(h5_path,'r') as h5:\n",
    "            X_Axis = h5[part_name]['Slice'+str(\"{:05d}\".format(num_slice+1))]['X-Axis']\n",
    "            x_axis_array = np.array(X_Axis)\n",
    "            minX.append(x_axis_array.min())\n",
    "            maxX.append(x_axis_array.max())\n",
    "    minX_array = np.asarray(minX)\n",
    "    maxX_array = np.asarray(maxX)\n",
    "    return minX_array.min(), maxX_array.max()\n",
    "#-----------------------------------------------------------------------\n",
    "def get_true_min_maxY (h5_path, part_name, max_slice_number):\n",
    "\n",
    "    minY = []\n",
    "    maxY = []\n",
    "    for num_slice in range(max_slice_number):\n",
    "        with h5py.File(h5_path,'r') as h5:\n",
    "            Y_Axis = h5[part_name]['Slice'+str(\"{:05d}\".format(num_slice+1))]['Y-Axis']\n",
    "            y_axis_array = np.array(Y_Axis)\n",
    "            minY.append(y_axis_array.min())\n",
    "            maxY.append(y_axis_array.max())\n",
    "    minY_array = np.asarray(minY)\n",
    "    maxY_array = np.asarray(maxY)\n",
    "    return minY_array.min(), maxY_array.max()\n",
    "#-----------------------------------------------------------------------\n",
    "def get_2D_data_from_h5_filtered(h5_path, part_name, Slice_name, mode):\n",
    "    #Step 1: getting the data from the h5\n",
    "    start_time = time.time()\n",
    "    with h5py.File(h5_path,'r') as h5:\n",
    "        X_Axis = h5[part_name][Slice_name]['X-Axis']\n",
    "        Y_Axis = h5[part_name][Slice_name]['Y-Axis']\n",
    "        Area = h5[part_name][Slice_name]['Area']\n",
    "        Intensity = h5[part_name][Slice_name]['Intensity']\n",
    "\n",
    "        X_Axis_size = X_Axis.size\n",
    "        Y_Axis_size = Y_Axis.size\n",
    "        Area_size = Area.size\n",
    "        Intensity_size = Intensity.size\n",
    "\n",
    "        #if dimensions aren't equal the following code block is entered\n",
    "        if not X_Axis_size == Y_Axis_size == Area_size == Intensity_size:\n",
    "\n",
    "            #determine the lowest value among the different sizes\n",
    "            size_arr = np.array([X_Axis_size, Y_Axis_size, Area_size, Intensity_size])\n",
    "            min_size = size_arr.min()\n",
    "\n",
    "            if X_Axis_size != min_size:\n",
    "                diff_size_x = X_Axis_size - min_size #calculating the difference between the actual value and the minimum and substracting it from the array\n",
    "                X_Axis_new = np.delete(X_Axis, -diff_size_x)\n",
    "                X_Axis = X_Axis_new\n",
    "                X_Axis_size = X_Axis.size\n",
    "\n",
    "            if Y_Axis_size != min_size:\n",
    "                diff_size_y = Y_Axis_size - min_size\n",
    "                Y_Axis_new = np.delete(Y_Axis, -diff_size_y)\n",
    "                Y_Axis = Y_Axis_new\n",
    "                Y_Axis_size = Y_Axis.size\n",
    "\n",
    "            if Area_size != min_size:\n",
    "                diff_size_area = Area_size - min_size\n",
    "                Area_new = np.delete(Area, -diff_size_area)\n",
    "                Area = Area_new\n",
    "                Area_size = Area.size\n",
    "\n",
    "            if Intensity_size != min_size:\n",
    "                diff_size_intensity = Intensity_size - min_size\n",
    "                Intensity_new = np.delete(Intensity, -diff_size_intensity)\n",
    "                Intensity = Intensity_new\n",
    "                Intensity_size = Intensity.size\n",
    "\n",
    "\n",
    "        #by reducing all the dimensions to the minimum equal dimensions are guaranteed\n",
    "        #there is a risk of deleting more than just one datapoint without noticing -> maybe add an alert after more than 5(?) while iterations\n",
    "        help_arr = np.column_stack((X_Axis, Y_Axis, Area, Intensity))\n",
    "        df_raw = pd.DataFrame(help_arr, columns=['x','y','area','intensity'])\n",
    "\n",
    "    #Step 2: change floats to ints and remove duplicates\n",
    "    df_int = df_raw.astype(int).drop_duplicates()\n",
    "\n",
    "    #remove all rows with 0 for area and intensity\n",
    "    df_int = df_int.loc[(df_int['area'] != 0) & (df_int['intensity'] != 0)]\n",
    "\n",
    "\n",
    "    #Step 3: Get a df with all the rows where a certain x,y combination occurs multiple times\n",
    "    df_multi_xy = df_int[df_int.duplicated(['x','y'], keep = False)].reset_index()\n",
    "\n",
    "    #Step 4: get a new df out of df_multi_xy with x,y and mean/max of area and intensity for all x,y occurences\n",
    "    df_compact = pd.DataFrame(columns=['x','y','area','intensity']) #initialize df_compact\n",
    "\n",
    "    print(\"till iterating from {} {} seconds ---\".format (Slice_name,time.time() - start_time))\n",
    "    for ind in range (df_multi_xy.shape[0]):\n",
    "        if mode == 'mean':\n",
    "            area_mean = df_multi_xy.loc[(df_multi_xy['x']== df_multi_xy.iloc[ind]['x']) & (df_multi_xy['y'] == df_multi_xy.iloc[ind]['y'])]['area'].mean().astype(int)\n",
    "            intensity_mean = df_multi_xy.loc[(df_multi_xy['x']== df_multi_xy.iloc[ind]['x']) & (df_multi_xy['y'] == df_multi_xy.iloc[ind]['y'])]['intensity'].mean().astype(int)\n",
    "            df_compact = df_compact.append({'x': df_multi_xy.iloc[ind]['x'], 'y':df_multi_xy.iloc[ind]['y'], 'area':area_mean , 'intensity':intensity_mean}, ignore_index=True)\n",
    "        if mode == 'max':\n",
    "            area_max = df_multi_xy.loc[(df_multi_xy['x']== df_multi_xy.iloc[ind]['x']) & (df_multi_xy['y'] == df_multi_xy.iloc[ind]['y'])]['area'].max().astype(int)\n",
    "            intensity_max = df_multi_xy.loc[(df_multi_xy['x']== df_multi_xy.iloc[ind]['x']) & (df_multi_xy['y'] == df_multi_xy.iloc[ind]['y'])]['intensity'].max().astype(int)\n",
    "            df_compact = df_compact.append({'x': df_multi_xy.iloc[ind]['x'], 'y':df_multi_xy.iloc[ind]['y'], 'area':area_max , 'intensity':intensity_max}, ignore_index=True)\n",
    "    df_compact = df_compact.drop_duplicates()\n",
    "\n",
    "    #Step 5: remove df_multi_xy from df_int and append df_compact\n",
    "    df_multi_xy_removed = df_int.drop(df_int[df_int.duplicated(['x','y'], keep = False)].index)\n",
    "\n",
    "    df_final = df_multi_xy_removed.append(df_compact)\n",
    "    print(\"df creation for {} took {} seconds ---\".format (Slice_name,time.time() - start_time))\n",
    "    return (df_final)\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "def create_single_voxel_df (current_n_vox_x, current_n_vox_y, voxel_size, df):\n",
    "    x_min_voxel = current_n_vox_x * voxel_size\n",
    "    x_max_voxel = (current_n_vox_x + 1)*voxel_size\n",
    "    y_min_voxel = current_n_vox_y * voxel_size\n",
    "    y_max_voxel = (current_n_vox_y + 1)*voxel_size\n",
    "\n",
    "    x_axis_voxel_df =  np.repeat(np.arange(x_min_voxel,x_max_voxel,1),voxel_size)\n",
    "    y_axis_voxel_df =  np.tile(np.arange(y_min_voxel,y_max_voxel,1),voxel_size)\n",
    "    Zero_array = np.zeros(voxel_size*voxel_size, dtype=int)\n",
    "\n",
    "    help_arr = np.column_stack((x_axis_voxel_df, y_axis_voxel_df, Zero_array, Zero_array))\n",
    "    df_voxel = pd.DataFrame(help_arr, columns=['x','y','area','intensity'])\n",
    "\n",
    "\n",
    "    if df[(df['x'] > x_min_voxel ) & (df['x'] < x_max_voxel ) & (df['y'] > y_min_voxel) & (df['y'] < y_max_voxel)].shape[0] != 0:\n",
    "        df_voxel_added = df_voxel.append(df[(df['x'] > x_min_voxel ) & (df['x'] < x_max_voxel ) & (df['y'] > y_min_voxel) & (df['y'] < y_max_voxel)])\n",
    "        df_voxel_wo_dupl = df_voxel_added.drop_duplicates(['x','y'], keep = 'last')\n",
    "        df_voxel_final = df_voxel_wo_dupl.sort_values(by=['x','y'])\n",
    "\n",
    "    else:\n",
    "        df_voxel_final = df_voxel\n",
    "\n",
    "    return df_voxel_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers_per_voxel = 10\n",
    "num_voxels_x = 20\n",
    "num_voxels_y = 20\n",
    "path_buildjob_h5 = '/home/jan/Documents/CodeTDMStoHDF/Ausgangsdaten/examplerRun.h5'\n",
    "path_voxel_h5_folder = '/home/jan/Documents/Voxel_Erstellung/HDFs/Versuchslauf_1'\n",
    "#name_voxel_h5_file = 'asdasd_2.hdf5'\n",
    "part_name = '0_00003_Canti3_cls'\n",
    "mode_df = 'mean' #way how to deal with data points which occur multiple times\n",
    "voxel_size = 100\n",
    "max_slice_number_part = 142 # doesn't need to be manually added\n",
    "os.mkdir(path_voxel_h5_folder)\n",
    "minX = int(get_true_min_maxX(path_buildjob_h5, part_name, max_slice_number_part)[0])\n",
    "maxX = int(get_true_min_maxX(path_buildjob_h5, part_name, max_slice_number_part)[1])\n",
    "minY = int(get_true_min_maxY(path_buildjob_h5, part_name, max_slice_number_part)[0])\n",
    "maxY = int(get_true_min_maxY(path_buildjob_h5, part_name, max_slice_number_part)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_vox_layer (num_z):\n",
    "    path = path_voxel_h5_folder + '/Voxel_layer:_{}.hdf5'.format(num_z)\n",
    "    start_time_1 = time.time()\n",
    "    for num_slice in range(num_layers_per_voxel*num_z, num_layers_per_voxel*(num_z+1)):\n",
    "        start_time_2 = time.time()\n",
    "        print('num_slice: ' + str(num_slice))\n",
    "        #start_time = time.time()\n",
    "        # getting the data of the part_hdf5\n",
    "        df_not_docked = get_2D_data_from_h5_filtered(path_buildjob_h5, part_name, 'Slice' + str(\"{:05d}\".format(num_slice+1)), mode_df) #\"{:05d}\" -> 1 becomes 00001 for accessibility in h5 file\n",
    "        df = dock_df_to_zero(df_not_docked, minX, minY) #docking the values of the dataframe to 0\n",
    "\n",
    "        for n_vox_y_init in range(num_voxels_y): #iterating over number of voxels in y-direction\n",
    "            #print('n_vox_y_init: ' + str(n_vox_y_init))\n",
    "            for n_vox_x_init in range(num_voxels_x):#iterating over number of voxels in x-direction\n",
    "                #print('n_vox_x_init: '+ str(n_vox_x_init))\n",
    "                df_voxel_final = create_single_voxel_df(n_vox_x_init, n_vox_y_init, voxel_size, df)\n",
    "\n",
    "                \n",
    "                #check if File is already existing -> path still needs to be defined \n",
    "                if not os.path.isfile(path):\n",
    "                    voxel_hdf = h5py.File(path, \"w\")\n",
    "                    voxel_hdf.close()\n",
    "                    \n",
    "                with h5py.File(path, \"a\") as voxel_hdf:\n",
    "                    #creating a voxel with the numbers of voxels in both direction in its name and filling it with data\n",
    "                    #if group is already existing don't create a new group\n",
    "                    if 'voxel_{}_{}_{}'.format(n_vox_x_init,n_vox_y_init, num_z) not in voxel_hdf:\n",
    "                        voxel_hdf.create_group('voxel_{}_{}_{}'.format(n_vox_x_init,n_vox_y_init,num_z))\n",
    "                    voxel_hdf['voxel_{}_{}_{}'.format(n_vox_x_init,n_vox_y_init,num_z)].create_group('slice_{}'.format(num_slice-num_z*num_layers_per_voxel)) #-num_z*num_slices_vox wegen\n",
    "                    voxel_hdf['voxel_{}_{}_{}'.format(n_vox_x_init,n_vox_y_init,num_z)]['slice_{}'.format(num_slice-num_z*num_layers_per_voxel)].create_dataset('X-Axis',data = np.repeat(np.arange(0,voxel_size,1),voxel_size))\n",
    "                    voxel_hdf['voxel_{}_{}_{}'.format(n_vox_x_init,n_vox_y_init,num_z)]['slice_{}'.format(num_slice-num_z*num_layers_per_voxel)].create_dataset('Y-Axis',data = np.tile(np.arange(0,voxel_size,1),voxel_size))\n",
    "                    voxel_hdf['voxel_{}_{}_{}'.format(n_vox_x_init,n_vox_y_init,num_z)]['slice_{}'.format(num_slice-num_z*num_layers_per_voxel)].create_dataset('Area', data = df_voxel_final['area'].values.astype(int))\n",
    "                    voxel_hdf['voxel_{}_{}_{}'.format(n_vox_x_init,n_vox_y_init,num_z)]['slice_{}'.format(num_slice-num_z*num_layers_per_voxel)].create_dataset('Intensity', data = df_voxel_final['intensity'].values.astype(int))\n",
    "        print('filling slice {} took {} s'.format(num_slice, time.time() - start_time_2))\n",
    "    print(\"layer filling took %s seconds ---\" % (time.time() - start_time_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_slice: 10\n",
      "till iterating from Slice00011 0.05177474021911621 seconds ---\n",
      "df creation for Slice00011 took 78.39901161193848 seconds ---\n",
      "filling slice 10 took 84.39902448654175 s\n",
      "num_slice: 11\n",
      "till iterating from Slice00012 0.04531288146972656 seconds ---\n",
      "df creation for Slice00012 took 71.6744430065155 seconds ---\n",
      "filling slice 11 took 77.27283692359924 s\n",
      "num_slice: 12\n",
      "till iterating from Slice00013 0.04584527015686035 seconds ---\n",
      "df creation for Slice00013 took 71.09422206878662 seconds ---\n",
      "filling slice 12 took 76.70865082740784 s\n",
      "num_slice: 13\n",
      "till iterating from Slice00014 0.03506803512573242 seconds ---\n",
      "df creation for Slice00014 took 75.26889061927795 seconds ---\n",
      "filling slice 13 took 80.92940354347229 s\n",
      "num_slice: 14\n",
      "till iterating from Slice00015 0.03848981857299805 seconds ---\n",
      "df creation for Slice00015 took 75.85409879684448 seconds ---\n",
      "filling slice 14 took 81.47097849845886 s\n",
      "num_slice: 15\n",
      "till iterating from Slice00016 0.0344080924987793 seconds ---\n",
      "df creation for Slice00016 took 75.44320440292358 seconds ---\n",
      "filling slice 15 took 81.10863780975342 s\n",
      "num_slice: 16\n",
      "till iterating from Slice00017 0.03994393348693848 seconds ---\n",
      "df creation for Slice00017 took 70.96481347084045 seconds ---\n",
      "filling slice 16 took 76.68285965919495 s\n",
      "num_slice: 17\n",
      "till iterating from Slice00018 0.04068565368652344 seconds ---\n",
      "df creation for Slice00018 took 70.58676242828369 seconds ---\n",
      "filling slice 17 took 76.21107792854309 s\n",
      "num_slice: 18\n",
      "till iterating from Slice00019 0.049180030822753906 seconds ---\n",
      "df creation for Slice00019 took 70.56152844429016 seconds ---\n",
      "filling slice 18 took 76.16256380081177 s\n",
      "num_slice: 19\n",
      "till iterating from Slice00020 0.049599409103393555 seconds ---\n",
      "df creation for Slice00020 took 71.12687683105469 seconds ---\n",
      "filling slice 19 took 77.28148698806763 s\n",
      "layer filling took 788.2280530929565 seconds ---\n"
     ]
    }
   ],
   "source": [
    "create_single_vox_layer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TDMS_env]",
   "language": "python",
   "name": "conda-env-TDMS_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
