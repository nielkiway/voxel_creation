{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import h5py\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2D_data_from_h5_filtered_np(h5_path, part_name, Slice_name):\n",
    "    #opening h5 and getting the data\n",
    "    start_time = time.time()\n",
    "    h5 = h5py.File(h5_path)                                          \n",
    "    Y_Axis = np.array(h5[part_name][Slice_name]['Y-Axis'][:]).astype(int)\n",
    "    Area = np.array(h5[part_name][Slice_name]['Area'][:]).astype(int)\n",
    "    Intensity = np.array(h5[part_name][Slice_name]['Intensity'][:]).astype(int)\n",
    "    X_Axis = np.array(h5[part_name][Slice_name]['X-Axis'][:]).astype(int)\n",
    "    h5.close()\n",
    "    \n",
    "    X_Axis_size = X_Axis.size\n",
    "    Y_Axis_size = Y_Axis.size\n",
    "    Area_size = Area.size\n",
    "    Intensity_size = Intensity.size\n",
    "\n",
    "    #if dimensions aren't equal the following code block is entered\n",
    "    if not X_Axis_size == Y_Axis_size == Area_size == Intensity_size:\n",
    "\n",
    "        #determine the lowest value among the different sizes\n",
    "        size_arr = np.array([X_Axis_size, Y_Axis_size, Area_size, Intensity_size])\n",
    "        min_size = size_arr.min()\n",
    "\n",
    "        if X_Axis_size != min_size:\n",
    "            diff_size_x = X_Axis_size - min_size #calculating the difference between the actual value and the minimum and substracting it from the array\n",
    "            X_Axis_new = np.delete(X_Axis, -diff_size_x)\n",
    "            X_Axis = X_Axis_new\n",
    "            X_Axis_size = X_Axis.size\n",
    "\n",
    "        if Y_Axis_size != min_size:\n",
    "            diff_size_y = Y_Axis_size - min_size\n",
    "            Y_Axis_new = np.delete(Y_Axis, -diff_size_y)\n",
    "            Y_Axis = Y_Axis_new\n",
    "            Y_Axis_size = Y_Axis.size\n",
    "\n",
    "        if Area_size != min_size:\n",
    "            diff_size_area = Area_size - min_size\n",
    "            Area_new = np.delete(Area, -diff_size_area)\n",
    "            Area = Area_new\n",
    "            Area_size = Area.size\n",
    "\n",
    "        if Intensity_size != min_size:\n",
    "            diff_size_intensity = Intensity_size - min_size\n",
    "            Intensity_new = np.delete(Intensity, -diff_size_intensity)\n",
    "            Intensity = Intensity_new\n",
    "            Intensity_size = Intensity.size\n",
    "                \n",
    "        #by reducing all the dimensions to the minimum equal dimensions are guaranteed\n",
    "        #there is a risk of deleting more than just one datapoint without noticing -> maybe add an alert after more than 5(?) while iterations\n",
    "    print(str(X_Axis_size)+ ' datapoints found')    \n",
    "    combos = np.stack((X_Axis, Y_Axis, Area, Intensity), axis=-1)\n",
    "\n",
    "    #filtering out the datapoints where area and intensity are =0\n",
    "    area_zeros = np.where(combos[:,2]== 0) \n",
    "    intensity_zeros = np.where(combos[:,3]==0)\n",
    "    zero_area_intensity_indices = np.intersect1d(area_zeros, intensity_zeros) #array of indices where area AND intensity are = 0\n",
    "\n",
    "    #deleting all the datapoints where area AND intensity are = 0\n",
    "    combos_wo_only_zeros = np.delete(combos, zero_area_intensity_indices, axis=0)\n",
    "    print(str(combos_wo_only_zeros.shape[0]) + ' datapoints where area != 0 AND intensity != 0')\n",
    "    \n",
    "    combos_wo_only_zeros_unique, unique_indices = np.unique(combos_wo_only_zeros[:,[0,1]],axis=0, return_index = True)\n",
    "    combos_unique = combos_wo_only_zeros[unique_indices]\n",
    "    print(str(combos_unique.shape[0]) + ' unique datapoints where area != 0 AND intensity != 0')\n",
    "    \n",
    "    Index_range = np.arange(combos_wo_only_zeros.shape[0])\n",
    "    indices_of_interest = np.setdiff1d(Index_range, unique_indices) #all the indices belonging to non unique x,y-combinations \n",
    "    \n",
    "    combo_processed_array = np.empty([0,4],dtype= int)\n",
    "    start_time = time.time()\n",
    "    combos_wo_only_zeros_copy = np.copy(combos_wo_only_zeros)\n",
    "    index_counter = 0\n",
    "    shape_counter = 0\n",
    "    indices_list = []\n",
    "    \n",
    "    print(time.time()-start\n",
    "\n",
    "    for index in indices_of_interest:\n",
    "        xy_combo = combos_wo_only_zeros[:,[0,1]][index]\n",
    "        if np.where((combo_processed_array[:,0] == xy_combo[0])*(combo_processed_array[:,1] == xy_combo[1]))[0].size == 0:\n",
    "            index_counter += 1\n",
    "            xy_combo = combos_wo_only_zeros[:,[0,1]][index]\n",
    "            indices_relevant = np.where((combos_wo_only_zeros[:,0] == xy_combo[0])*(combos_wo_only_zeros[:,1] == xy_combo[1]))[0]\n",
    "            max_area_of_combo = np.amax(combos_wo_only_zeros[:,2][indices_relevant])\n",
    "            max_intensity_of_combo = np.amax(combos_wo_only_zeros[:,3][indices_relevant])\n",
    "\n",
    "            max_combos = np.stack((xy_combo[0], xy_combo[1], max_area_of_combo, max_intensity_of_combo), axis=-1)\n",
    "\n",
    "            combos_wo_only_zeros_copy = np.vstack((combos_wo_only_zeros_copy, max_combos))\n",
    "            shape_counter += indices_relevant.shape[0]\n",
    "            indices_list.append(list(indices_relevant))\n",
    "\n",
    "            combo_processed_array =  np.vstack((combo_processed_array, max_combos))\n",
    "\n",
    "    indices_relevant = np.hstack(indices_list) \n",
    "    combos_wo_only_zeros_copy = np.delete(combos_wo_only_zeros_copy, indices_relevant, axis = 0)   \n",
    "    print (time.time()-start_time)\n",
    "    return(combos_wo_only_zeros_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = '/home/jan/Documents/CodeTDMStoHDF/Ausgangsdaten/examplerRun.h5'\n",
    "Slice_name = 'Slice00065'\n",
    "part_name = '0_00003_Canti3_cls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143642 datapoints found\n",
      "81568 datapoints where area != 0 AND intensity != 0\n",
      "64081 unique datapoints where area != 0 AND intensity != 0\n",
      "17.36192226409912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 10950, -25033,     59,      0],\n",
       "       [ 10935, -25033,    118,    506],\n",
       "       [ 10928, -25033,    166,    584],\n",
       "       ...,\n",
       "       [ 10885, -19584,    230,    537],\n",
       "       [ 10966, -19624,    684,   1524],\n",
       "       [ 10965, -19584,    254,    453]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_2D_data_from_h5_filtered_np('/home/jan/Documents/CodeTDMStoHDF/Ausgangsdaten/examplerRun.h5','0_00003_Canti3_cls','Slice00064')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TDMS_env]",
   "language": "python",
   "name": "conda-env-TDMS_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
